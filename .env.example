# Somali NLP Data Pipeline - Environment Configuration Template
# Copy this file to .env and fill in your actual values

# ============================================================================
# TikTok Apify Configuration
# ============================================================================
# Required for TikTok data collection via Apify API
# Get your token at: https://console.apify.com/account/integrations
SDC_SCRAPING__TIKTOK__APIFY_API_TOKEN=your_apify_api_token_here

# Optional: Your Apify user ID for reference
# SDC_SCRAPING__TIKTOK__APIFY_USER_ID=your_user_id_here

# ============================================================================
# Pipeline Configuration (Optional)
# ============================================================================
# Uncomment and modify as needed

# Environment mode (development, production)
# ENV=development

# Logging level (DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL=INFO

# ============================================================================
# Data Paths (Optional - uses defaults if not set)
# ============================================================================
# SDC_DATA_DIR=data
# SDC_LOGS_DIR=logs
# SDC_BACKUP_DIR=backups

# ============================================================================
# Orchestration Configuration
# ============================================================================
# Controls the initial collection phase and per-source refresh cadences

# Initial collection phase duration (1-30 days)
# All sources run daily during this phase to build initial dataset
SDC_ORCHESTRATION__INITIAL_COLLECTION_DAYS=7

# Default refresh cadence (1-365 days)
# Used for sources not explicitly configured
SDC_ORCHESTRATION__DEFAULT_CADENCE_DAYS=7

# Per-source refresh cadences (days)
# Wikipedia: Encyclopedia content, weekly updates
SDC_ORCHESTRATION__CADENCE_DAYS__WIKIPEDIA=7

# BBC Somali: News content, weekly refresh
SDC_ORCHESTRATION__CADENCE_DAYS__BBC=7

# HuggingFace: Large dataset, monthly updates
SDC_ORCHESTRATION__CADENCE_DAYS__HUGGINGFACE=30

# Språkbanken: Academic corpus, quarterly updates
SDC_ORCHESTRATION__CADENCE_DAYS__SPRAKBANKEN=90

# TikTok: Social media, weekly with manual scheduling
SDC_ORCHESTRATION__CADENCE_DAYS__TIKTOK=7

# ============================================================================
# Daily Quota Limits (Production Rate Limiting)
# ============================================================================
# Controls maximum records ingested per source per day
# Prevents excessive API costs and respects rate limits

# BBC: 350 articles/day - respects ethical scraping limits
SDC_ORCHESTRATION__QUOTA_LIMITS__BBC=350

# HuggingFace: 10,000 records/day - throttles large dataset processing
SDC_ORCHESTRATION__QUOTA_LIMITS__HUGGINGFACE=10000

# Språkbanken: 10 corpora/day - paces academic corpus downloads
SDC_ORCHESTRATION__QUOTA_LIMITS__SPRAKBANKEN=10

# Wikipedia: No quota (file-based, efficient)
# TikTok: No quota (manual scheduling with cost gating)

# ============================================================================
# Backup Configuration (Optional)
# ============================================================================
# Backup retention period (days)
# SDC_BACKUP__RETENTION_DAYS=30

# Backup schedule (for automated backups)
# SDC_BACKUP__SCHEDULE=daily

# ============================================================================
# PostgreSQL Configuration (Optional - for production scale)
# ============================================================================
# PostgreSQL connection settings
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DB=somali_nlp
# POSTGRES_USER=somali

# CRITICAL SECURITY: Database password is REQUIRED for PostgreSQL backend
# Set one of the following (SDC_DB_PASSWORD takes precedence):
# SDC_DB_PASSWORD=your_secure_password_here
# POSTGRES_PASSWORD=your_secure_password_here
#
# NEVER use hardcoded passwords in production
# NEVER commit .env files to version control
# Use strong passwords (16+ characters, mixed case, numbers, symbols)
# POSTGRES_AUTH_METHOD=md5

# ============================================================================
# Ledger Backend Selection (Optional)
# ============================================================================
# Backend selection: sqlite (default for dev) or postgres (for production)
# SDC_LEDGER_BACKEND=sqlite

# SQLite database path (fallback for dev)
# SDC_LEDGER_SQLITE_PATH=data/ledger/crawl_ledger.db

# ============================================================================
# Performance & Reliability Configuration
# ============================================================================

# HTTP request timeout (seconds) - applies to all web scraping
# Increase for slow networks or large responses
SDC_HTTP__REQUEST_TIMEOUT=30

# PostgreSQL query timeout (seconds)
# Prevents runaway queries from blocking the pipeline
SDC_DB__QUERY_TIMEOUT=30

# Database connection pool size
# Increase for concurrent pipeline execution
SDC_DB__POOL_SIZE=5
SDC_DB__MAX_OVERFLOW=10

# XML/HTML parsing buffer size (MB)
# Increase for very large documents, decrease for memory-constrained environments
SDC_PARSING__BUFFER_SIZE_MB=10

# Disk space safety threshold (GB)
# Pipeline aborts if free disk space falls below this threshold
SDC_DISK__MIN_FREE_SPACE_GB=10
