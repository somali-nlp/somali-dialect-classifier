name: Deploy Enhanced Dashboard to GitHub Pages

on:
  push:
    branches:
      - main
    paths:
      - 'data/metrics/**'
      - 'data/reports/**'
      - 'dashboard/**'
      - '.github/workflows/deploy-dashboard-v2.yml'
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install streamlit pandas plotly numpy

      - name: Build dashboard site
        run: |
          # Step 1: Create site structure and copy static assets
          # - Creates _site/ and _site/data/ directories
          # - Copies index.html template
          # - Copies favicon, metrics/, and reports/ directories
          # - Does NOT generate all_metrics.json (done in next step)
          chmod +x dashboard/build-site.sh
          ./dashboard/build-site.sh

      - name: Generate metrics data
        run: |
          # Step 2: Process raw metrics and generate aggregated JSON
          # - Reads all *_processing.json files from data/metrics/
          # - Calculates aggregates (total records, sources, etc.)
          # - Generates _site/data/all_metrics.json for dashboard consumption
          # - This step MUST run after build-site.sh to ensure directories exist
          python << 'PYTHON_SCRIPT'
          import json
          from pathlib import Path
          from datetime import datetime

          # Create data directory (redundant with build-site.sh, but ensures it exists)
          site_data = Path("_site/data")
          site_data.mkdir(parents=True, exist_ok=True)

          # Load all metrics (only processing phase for accurate success rates)
          metrics_dir = Path("data/metrics")
          all_metrics = []

          if metrics_dir.exists():
              for metrics_file in metrics_dir.glob("*_processing.json"):
                  try:
                      with open(metrics_file) as f:
                          data = json.load(f)
                          snapshot = data.get("snapshot", {})
                          stats = data.get("statistics", {})
                          perf = stats.get("throughput", {})
                          quality = stats.get("text_length_stats", {})

                          all_metrics.append({
                              "run_id": snapshot.get("run_id", ""),
                              "source": snapshot.get("source", ""),
                              "timestamp": snapshot.get("timestamp", ""),
                              "duration_seconds": snapshot.get("duration_seconds", 0),
                              "urls_discovered": snapshot.get("urls_discovered", 0),
                              "urls_fetched": snapshot.get("urls_fetched", 0),
                              "urls_processed": snapshot.get("urls_processed", 0),
                              "records_written": snapshot.get("records_written", 0),
                              "bytes_downloaded": snapshot.get("bytes_downloaded", 0),
                              "success_rate": stats.get("fetch_success_rate", 0),
                              "deduplication_rate": stats.get("deduplication_rate", 0),
                              "performance": {
                                  "urls_per_second": perf.get("urls_per_second", 0),
                                  "bytes_per_second": perf.get("bytes_per_second", 0),
                                  "records_per_minute": perf.get("records_per_minute", 0)
                              },
                              "quality": {
                                  "min": quality.get("min", 0),
                                  "max": quality.get("max", 0),
                                  "mean": quality.get("mean", 0),
                                  "median": quality.get("median", 0),
                                  "total_chars": quality.get("total_chars", 0)
                              }
                          })
                  except Exception as e:
                      print(f"Error loading {metrics_file}: {e}")

          # Calculate aggregates
          if all_metrics:
              total_records = sum(m["records_written"] for m in all_metrics)
              sources = sorted(list(set(m["source"] for m in all_metrics)))

              # Save all metrics
              output = {
                  "count": len(all_metrics),
                  "records": total_records,
                  "sources": sources,
                  "metrics": all_metrics
              }

              with open("_site/data/all_metrics.json", "w") as f:
                  json.dump(output, f, indent=2)

              print(f"âœ… Generated metrics: {len(all_metrics)} runs, {total_records:,} records")
              print(f"âœ… Sources: {', '.join(sources)}")
          else:
              # No metrics found - create empty files
              print("âš ï¸  No metrics found - creating empty state")

              empty_output = {
                  "count": 0,
                  "records": 0,
                  "sources": [],
                  "metrics": []
              }

              with open("_site/data/all_metrics.json", "w") as f:
                  json.dump(empty_output, f, indent=2)

              print("âœ… Created empty metrics files")
          PYTHON_SCRIPT

      - name: Verify build
        run: |
          # Step 3: Verify all required files are present before deployment
          # - Ensures _site/data/all_metrics.json exists (critical for dashboard)
          # - Displays structure and content preview
          echo "ðŸ“¦ Build verification:"
          echo ""
          echo "ðŸ“„ Site structure:"
          ls -lh _site/
          echo ""
          echo "ðŸ“ Data directory:"
          ls -lh _site/data/
          echo ""
          if [ -f "_site/data/all_metrics.json" ]; then
            echo "âœ… all_metrics.json exists"
            echo "ðŸ“Š Metrics preview:"
            head -20 _site/data/all_metrics.json
          else
            echo "âŒ ERROR: all_metrics.json not found!"
            exit 1
          fi
          echo ""
          echo "âœ… Build verification complete"

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '_site'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Summary
        run: |
          echo "ðŸš€ Deployment complete!"
          echo "ðŸ“Š Dashboard URL: https://somali-nlp.github.io/somali-dialect-classifier/"
