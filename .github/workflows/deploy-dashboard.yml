name: Deploy Dashboard to GitHub Pages

on:
  push:
    branches:
      - main
    paths:
      - 'data/metrics/**'
      - 'data/reports/**'
      - 'dashboard/**'
      - '.github/workflows/deploy-dashboard.yml'
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install streamlit pandas plotly numpy


      - name: Build static dashboard
        run: |
          # Deploy advanced D3.js dashboard with NY Times-style visualizations
          mkdir -p _site
          
          # Copy the advanced dashboard as main page
          cp dashboard/index-advanced.html _site/index.html
          
          echo "âœ… Deployed advanced D3.js dashboard to _site/index.html"
          echo "ðŸ“Š Features: Bubble timeline, radial comparison, horizon charts, hexbin heatmap, streamgraph"

      - name: Generate dashboard data
        run: |
          python << 'PYTHON_SCRIPT'
          import json
          from pathlib import Path
          from datetime import datetime

          # Create data directory
          site_data = Path("_site/data")
          site_data.mkdir(parents=True, exist_ok=True)

          # Load all metrics (only processing phase for accurate success rates)
          metrics_dir = Path("data/metrics")
          all_metrics = []

          if metrics_dir.exists():
              for metrics_file in metrics_dir.glob("*_processing.json"):
                  try:
                      with open(metrics_file) as f:
                          data = json.load(f)
                          snapshot = data.get("snapshot", {})
                          stats = data.get("statistics", {})

                          all_metrics.append({
                              "run_id": snapshot.get("run_id", ""),
                              "source": snapshot.get("source", ""),
                              "timestamp": snapshot.get("timestamp", ""),
                              "records_written": snapshot.get("records_written", 0),
                              "success_rate": stats.get("fetch_success_rate", 0),
                              "deduplication_rate": stats.get("deduplication_rate", 0),
                              "urls_discovered": snapshot.get("urls_discovered", 0),
                              "urls_fetched": snapshot.get("urls_fetched", 0),
                              "urls_processed": snapshot.get("urls_processed", 0),
                              "urls_failed": snapshot.get("urls_failed", 0),
                              "http_status_codes": snapshot.get("http_status_codes", {}),
                              "error_types": snapshot.get("error_types", {}),
                              "pipeline_type": snapshot.get("pipeline_type", ""),
                          })
                  except Exception as e:
                      print(f"Error loading {metrics_file}: {e}")

          # Generate summary
          if all_metrics:
              summary = {
                  "total_records": sum(m["records_written"] for m in all_metrics),
                  "avg_success_rate": sum(m["success_rate"] for m in all_metrics) / len(all_metrics),
                  "sources": list(set(m["source"] for m in all_metrics)),
                  "last_update": max(m["timestamp"] for m in all_metrics),
                  "total_runs": len(all_metrics)
              }
          else:
              summary = {
                  "total_records": 0,
                  "avg_success_rate": 0,
                  "sources": [],
                  "last_update": datetime.now().isoformat(),
                  "total_runs": 0
              }

          # Save summary
          with open(site_data / "summary.json", "w") as f:
              json.dump(summary, f, indent=2)

          # Save all metrics for chart rendering
          with open(site_data / "all_metrics.json", "w") as f:
              json.dump(all_metrics, f, indent=2)

          # Copy reports
          import shutil
          reports_dir = Path("data/reports")
          if reports_dir.exists():
              site_reports = Path("_site/reports")
              site_reports.mkdir(exist_ok=True)

              report_list = []
              for report in reports_dir.glob("*_final_quality_report.md"):
                  # Copy report
                  shutil.copy(report, site_reports / report.name)

                  report_list.append({
                      "name": report.stem.replace("_final_quality_report", ""),
                      "filename": report.name
                  })

              # Save report list
              with open(site_data / "reports.json", "w") as f:
                  json.dump(report_list, f, indent=2)
          else:
              # Create empty reports list if no reports exist
              with open(site_data / "reports.json", "w") as f:
                  json.dump([], f, indent=2)

          print(f"Generated dashboard data: {len(all_metrics)} metrics, {summary['total_records']} total records")

          # List generated files for debugging
          import os
          for root, dirs, files in os.walk("_site"):
              for file in files:
                  print(f"  - {os.path.join(root, file)}")
          PYTHON_SCRIPT

      - name: Verify build artifacts
        run: |
          echo "ðŸ“ Checking _site directory structure:"
          ls -la _site/
          echo ""
          echo "ðŸ“ Checking data directory:"
          ls -la _site/data/ || echo "No data directory"
          echo ""
          echo "ðŸ“‹ Checking summary.json:"
          if [ -f _site/data/summary.json ]; then
            head -5 _site/data/summary.json
          else
            echo "ERROR: summary.json not found!"
          fi

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '_site'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Summary
        run: |
          echo "### ðŸš€ Dashboard Deployed Successfully" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š **Dashboard URL**: https://${{ github.repository_owner }}.github.io/somali-dialect-classifier/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "To run the interactive dashboard locally:" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "streamlit run dashboard/app.py" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
